"use strict";(self.webpackChunkdocosaurus_test=self.webpackChunkdocosaurus_test||[]).push([[6641],{746:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>i,contentTitle:()=>c,default:()=>d,frontMatter:()=>o,metadata:()=>r,toc:()=>l});var s=t(4848),a=t(8453);const o={slug:"test-eks-post",title:"Test EKS Post",authors:"Petr Ruzicka",date:new Date("2020-12-10T00:00:00.000Z"),categories:["EKS","Pipelines"],tags:["EKS","Pipeline Templates"]},c="Amazon EKS Bottlerocket and Fargate",r={permalink:"/docosaurus-test/blog/test-eks-post",editUrl:"https://github.com/ruzickap/blog-test.ruzicka.dev/tree/main/docosaurus-test/blog/2020/2020-12-10-eks-test.md",source:"@site/blog/2020/2020-12-10-eks-test.md",title:"Test EKS Post",description:"![Amazon EKS](https://raw.githubusercontent.com/cncf/landscape/7f5b02ecba914a32912e77fc78e1c54d1c2f98ec/hosted_logos/amazon-eks.svg?sanitize=true",date:"2020-12-10T00:00:00.000Z",tags:[{inline:!0,label:"EKS",permalink:"/docosaurus-test/blog/tags/eks"},{inline:!0,label:"Pipeline Templates",permalink:"/docosaurus-test/blog/tags/pipeline-templates"}],readingTime:21.465,hasTruncateMarker:!1,authors:[{name:"Petr Ruzicka",title:"Blog owner",url:"https://petr.ruzicka.dev",imageURL:"https://github.com/ruzickap.png",key:"Petr Ruzicka"}],frontMatter:{slug:"test-eks-post",title:"Test EKS Post",authors:"Petr Ruzicka",date:"2020-12-10T00:00:00.000Z",categories:["EKS","Pipelines"],tags:["EKS","Pipeline Templates"]},unlisted:!1,prevItem:{title:"MDX Blog Post",permalink:"/docosaurus-test/blog/mdx-blog-post"},nextItem:{title:"Image Test EKS Post",permalink:"/docosaurus-test/blog/image-test-eks-post"}},i={authorsImageUrls:[void 0]},l=[{value:"Requirements",id:"requirements",level:2},{value:"Prepare the local working environment",id:"prepare-the-local-working-environment",level:2},{value:"Configure AWS Route 53 Domain delegation",id:"configure-aws-route-53-domain-delegation",level:2},{value:"Add new domain to Route 53, Policies, S3, EBS",id:"add-new-domain-to-route-53-policies-s3-ebs",level:2},{value:"Create Amazon EKS",id:"create-amazon-eks",level:2}];function u(e){const n={a:"a",code:"code",h2:"h2",img:"img",li:"li",p:"p",pre:"pre",ul:"ul",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{src:"https://raw.githubusercontent.com/cncf/landscape/7f5b02ecba914a32912e77fc78e1c54d1c2f98ec/hosted_logos/amazon-eks.svg?sanitize=true",alt:"Amazon EKS",title:"Amazon EKS"})}),"\n",(0,s.jsxs)(n.p,{children:["Before starting with the main content, it's necessary to provision\nthe ",(0,s.jsx)(n.a,{href:"https://aws.amazon.com/eks/",children:"Amazon EKS"})," in AWS."]}),"\n",(0,s.jsx)(n.h2,{id:"requirements",children:"Requirements"}),"\n",(0,s.jsx)(n.p,{children:"If you would like to follow this documents and it's task you will need to set up\nfew environment variables."}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"LETSENCRYPT_ENVIRONMENT"})," variable should be one of:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"staging"})," - Let\u2019s Encrypt will create testing certificate (not valid)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"production"})," - Let\u2019s Encrypt will create valid certificate (use with care)"]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"BASE_DOMAIN"})," contains DNS records for all your Kubernetes clusters. The cluster\nnames will look like ",(0,s.jsx)(n.code,{children:"CLUSTER_NAME"}),".",(0,s.jsx)(n.code,{children:"BASE_DOMAIN"})," (",(0,s.jsx)(n.code,{children:"kube1.k8s.mylabs.dev"}),")."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'# Hostname / FQDN definitions\nexport BASE_DOMAIN=${BASE_DOMAIN:-k8s.mylabs.dev}\nexport CLUSTER_NAME=${CLUSTER_NAME:-kube1}\nexport CLUSTER_FQDN="${CLUSTER_NAME}.${BASE_DOMAIN}"\nexport KUBECONFIG=${PWD}/kubeconfig-${CLUSTER_NAME}.conf\n# * "production" - valid certificates signed by Lets Encrypt ""\n# * "staging" - not trusted certs signed by Lets Encrypt "Fake LE Intermediate X1"\nexport LETSENCRYPT_ENVIRONMENT="staging"\nexport LETSENCRYPT_CERTIFICATE="https://letsencrypt.org/certs/staging/letsencrypt-stg-root-x1.pem"\n# export LETSENCRYPT_ENVIRONMENT="production"\n# export LETSENCRYPT_CERTIFICATE="https://letsencrypt.org/certs/lets-encrypt-r3.pem"\nexport MY_EMAIL="petr.ruzicka@gmail.com"\n# GitHub Organization + Team where are the users who will have the admin access\n# to K8s resources (Grafana). Only users in GitHub organization\n# (MY_GITHUB_ORG_NAME) will be able to access the apps via ingress.\nexport MY_GITHUB_ORG_NAME="ruzickap-org"\nexport MY_GITHUB_USERNAME="ruzickap"\n# AWS Region\nexport AWS_DEFAULT_REGION="eu-west-1"\nexport SLACK_CHANNEL="mylabs"\n# Tags used to tag the AWS resources\nexport TAGS="Owner=${MY_EMAIL} Environment=Dev Group=Cloud_Native Squad=Cloud_Container_Platform compliance:na:defender=bottlerocket"\necho -e "${MY_EMAIL} | ${LETSENCRYPT_ENVIRONMENT} | ${CLUSTER_NAME} | ${BASE_DOMAIN} | ${CLUSTER_FQDN}\\n${TAGS}"\n'})}),"\n",(0,s.jsx)(n.p,{children:'Prepare GitHub OAuth "access" credentials ans AWS "access" variables.'}),"\n",(0,s.jsxs)(n.p,{children:["You will need to configure AWS CLI: ",(0,s.jsx)(n.a,{href:"https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html",children:"Configuring the AWS CLI"})]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-shell",children:'# Common password\nexport MY_PASSWORD="xxxx"\n# AWS Credentials\nexport AWS_ACCESS_KEY_ID=""\nexport AWS_SECRET_ACCESS_KEY=""\nexport AWS_CONSOLE_ADMIN_ROLE_ARN="arn:aws:iam::7xxxxxxxxxx7:role/xxxxxxxxxxxxxN"\n# GitHub Organization OAuth Apps credentials\nexport MY_GITHUB_ORG_OAUTH_DEX_CLIENT_ID="3xxxxxxxxxxxxxxxxxx3"\nexport MY_GITHUB_ORG_OAUTH_DEX_CLIENT_SECRET="7xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx8"\nexport MY_GITHUB_ORG_OAUTH_KEYCLOAK_CLIENT_ID="4xxxxxxxxxxxxxxxxxx4"\nexport MY_GITHUB_ORG_OAUTH_KEYCLOAK_CLIENT_SECRET="7xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxa"\n# Sysdig credentials\nexport SYSDIG_AGENT_ACCESSKEY="xxx"\n# Aqua credentials\nexport AQUA_REGISTRY_USERNAME="xxx"\nexport AQUA_REGISTRY_PASSWORD="xxx"\nexport AQUA_ENFORCER_TOKEN="xxx"\n# Splunk credentials\nexport SPLUNK_HOST="xxx"\nexport SPLUNK_TOKEN="xxx"\nexport SPLUNK_INDEX_NAME="xxx"\n# Slack incoming webhook\nexport SLACK_INCOMING_WEBHOOK_URL="https://hooks.slack.com/services/YOUR/SLACK/WEBHOOK"\nexport SLACK_BOT_API_TOKEN="xxxx-xxxxxxxxxxxxx-xxxxxxxxxxxxx-xxxxxxxxxxxxxxxxxxxxxxxP"\n# Okta configuration\nexport OKTA_ISSUER="https://exxxxxxx-xxxxx-xx.okta.com"\nexport OKTA_CLIENT_ID="0xxxxxxxxxxxxxxxxxx7"\nexport OKTA_CLIENT_SECRET="1xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxH"\n'})}),"\n",(0,s.jsx)(n.p,{children:"Verify if all the necessary variables were set:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'case "${CLUSTER_NAME}" in\n  kube1)\n    MY_GITHUB_ORG_OAUTH_DEX_CLIENT_ID=${MY_GITHUB_ORG_OAUTH_DEX_CLIENT_ID:-${MY_GITHUB_ORG_OAUTH_DEX_CLIENT_ID_KUBE1}}\n    MY_GITHUB_ORG_OAUTH_DEX_CLIENT_SECRET=${MY_GITHUB_ORG_OAUTH_DEX_CLIENT_SECRET:-${MY_GITHUB_ORG_OAUTH_DEX_CLIENT_SECRET_KUBE1}}\n    MY_GITHUB_ORG_OAUTH_KEYCLOAK_CLIENT_ID=${MY_GITHUB_ORG_OAUTH_KEYCLOAK_CLIENT_ID:-${MY_GITHUB_ORG_OAUTH_KEYCLOAK_CLIENT_ID_KUBE1}}\n    MY_GITHUB_ORG_OAUTH_KEYCLOAK_CLIENT_SECRET=${MY_GITHUB_ORG_OAUTH_KEYCLOAK_CLIENT_SECRET:-${MY_GITHUB_ORG_OAUTH_KEYCLOAK_CLIENT_SECRET_KUBE1}}\n    ;;\n  kube2)\n    MY_GITHUB_ORG_OAUTH_DEX_CLIENT_ID=${MY_GITHUB_ORG_OAUTH_DEX_CLIENT_ID:-${MY_GITHUB_ORG_OAUTH_DEX_CLIENT_ID_KUBE2}}\n    MY_GITHUB_ORG_OAUTH_DEX_CLIENT_SECRET=${MY_GITHUB_ORG_OAUTH_DEX_CLIENT_SECRET:-${MY_GITHUB_ORG_OAUTH_DEX_CLIENT_SECRET_KUBE2}}\n    MY_GITHUB_ORG_OAUTH_KEYCLOAK_CLIENT_ID=${MY_GITHUB_ORG_OAUTH_KEYCLOAK_CLIENT_ID:-${MY_GITHUB_ORG_OAUTH_KEYCLOAK_CLIENT_ID_KUBE2}}\n    MY_GITHUB_ORG_OAUTH_KEYCLOAK_CLIENT_SECRET=${MY_GITHUB_ORG_OAUTH_KEYCLOAK_CLIENT_SECRET:-${MY_GITHUB_ORG_OAUTH_KEYCLOAK_CLIENT_SECRET_KUBE2}}\n    ;;\n  *)\n    echo "Unsupported cluster name: ${CLUSTER_NAME} !"\n    exit 1\n    ;;\nesac\n\n: "${AWS_ACCESS_KEY_ID?}"\n: "${AWS_SECRET_ACCESS_KEY?}"\n: "${AWS_CONSOLE_ADMIN_ROLE_ARN?}"\n: "${GITHUB_TOKEN?}"\n: "${SLACK_INCOMING_WEBHOOK_URL?}"\n: "${SLACK_BOT_API_TOKEN?}"\n: "${MY_PASSWORD?}"\n: "${OKTA_ISSUER?}"\n: "${OKTA_CLIENT_ID?}"\n: "${OKTA_CLIENT_SECRET?}"\n'})}),"\n",(0,s.jsx)(n.h2,{id:"prepare-the-local-working-environment",children:"Prepare the local working environment"}),"\n",(0,s.jsx)(n.p,{children:"::: tip\nYou can skip these steps if you have all the required software already\ninstalled.\n:::"}),"\n",(0,s.jsx)(n.p,{children:"Install necessary software:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"\nif command -v apt-get &> /dev/null; then\n  apt update -qq\n  DEBIAN_FRONTEND=noninteractive apt-get install -y -qq apache2-utils ansible dnsutils git gnupg2 jq sudo unzip > /dev/null\nfi\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Install ",(0,s.jsx)(n.a,{href:"https://aws.amazon.com/cli/",children:"AWS CLI"}),"  binary:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'if ! command -v aws &> /dev/null; then\n  curl -sL "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o "/tmp/awscliv2.zip"\n  unzip -q -o /tmp/awscliv2.zip -d /tmp/\n  sudo /tmp/aws/install\nfi\n'})}),"\n",(0,s.jsxs)(n.p,{children:["Install ",(0,s.jsx)(n.a,{href:"https://github.com/kubernetes/kubectl",children:"kubectl"})," binary:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'if ! command -v kubectl &> /dev/null; then\n  # https://github.com/kubernetes/kubectl/releases\n  sudo curl -s -Lo /usr/local/bin/kubectl "https://storage.googleapis.com/kubernetes-release/release/v1.21.1/bin/$(uname | sed "s/./\\L&/g")/amd64/kubectl"\n  sudo chmod a+x /usr/local/bin/kubectl\nfi\n'})}),"\n",(0,s.jsxs)(n.p,{children:["Install ",(0,s.jsx)(n.a,{href:"https://helm.sh/",children:"Helm"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"if ! command -v helm &> /dev/null; then\n  # https://github.com/helm/helm/releases\n  curl -s https://raw.githubusercontent.com/helm/helm/master/scripts/get | bash -s -- --version v3.6.0\nfi\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Install ",(0,s.jsx)(n.a,{href:"https://eksctl.io/",children:"eksctl"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'if ! command -v eksctl &> /dev/null; then\n  # https://github.com/weaveworks/eksctl/releases\n  curl -s -L "https://github.com/weaveworks/eksctl/releases/download/0.60.0/eksctl_$(uname)_amd64.tar.gz" | sudo tar xz -C /usr/local/bin/\nfi\n'})}),"\n",(0,s.jsxs)(n.p,{children:["Install ",(0,s.jsx)(n.a,{href:"https://github.com/kubernetes-sigs/aws-iam-authenticator",children:"AWS IAM Authenticator for Kubernetes"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'if ! command -v aws-iam-authenticator &> /dev/null; then\n  # https://docs.aws.amazon.com/eks/latest/userguide/install-aws-iam-authenticator.html\n  sudo curl -s -Lo /usr/local/bin/aws-iam-authenticator "https://amazon-eks.s3.us-west-2.amazonaws.com/1.19.6/2021-01-05/bin/$(uname | sed "s/./\\L&/g")/amd64/aws-iam-authenticator"\n  sudo chmod a+x /usr/local/bin/aws-iam-authenticator\nfi\n'})}),"\n",(0,s.jsxs)(n.p,{children:["Install ",(0,s.jsx)(n.a,{href:"https://www.vaultproject.io/downloads",children:"vault"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'if ! command -v vault &> /dev/null; then\n  curl -s -L "https://releases.hashicorp.com/vault/1.7.2/vault_1.7.2_$(uname | sed "s/./\\L&/g")_amd64.zip" -o /tmp/vault.zip\n  sudo unzip -q /tmp/vault.zip -d /usr/local/bin/\n  rm /tmp/vault.zip\nfi\n'})}),"\n",(0,s.jsxs)(n.p,{children:["Install ",(0,s.jsx)(n.a,{href:"https://github.com/vmware-tanzu/velero/releases",children:"velero"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'if ! command -v velero &> /dev/null; then\n  curl -s -L "https://github.com/vmware-tanzu/velero/releases/download/v1.6.0/velero-v1.6.0-$(uname | sed "s/./\\L&/g")-amd64.tar.gz" -o /tmp/velero.tar.gz\n  sudo tar xzf /tmp/velero.tar.gz -C /usr/local/bin/ --strip-components 1 "velero-v1.6.0-$(uname | sed "s/./\\L&/g")-amd64/velero"\nfi\n'})}),"\n",(0,s.jsxs)(n.p,{children:["Install ",(0,s.jsx)(n.a,{href:"https://toolkit.fluxcd.io/",children:"flux"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"if ! command -v flux &> /dev/null; then\n  curl -s https://fluxcd.io/install.sh | sudo bash\nfi\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Install ",(0,s.jsx)(n.code,{children:"calicoctl"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"if ! command -v calicoctl &> /dev/null; then\n  sudo curl -s -Lo /usr/local/bin/calicoctl https://github.com/projectcalico/calicoctl/releases/download/v3.20.0/calicoctl\n  sudo chmod a+x /usr/local/bin/calicoctl\nfi\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Install ",(0,s.jsx)(n.a,{href:"https://github.com/mozilla/sops",children:"SOPS: Secrets OPerationS"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'if ! command -v sops &> /dev/null; then\n  sudo curl -s -Lo /usr/local/bin/sops "https://github.com/mozilla/sops/releases/download/v3.7.1/sops-v3.7.1.$(uname | sed "s/./\\L&/g")"\n  sudo chmod a+x /usr/local/bin/sops\nfi\n'})}),"\n",(0,s.jsxs)(n.p,{children:["Install ",(0,s.jsx)(n.a,{href:"https://kustomize.io/",children:"kustomize"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'if ! command -v kustomize &> /dev/null; then\n  curl -s "https://raw.githubusercontent.com/kubernetes-sigs/kustomize/master/hack/install_kustomize.sh" | sudo bash -s 4.1.2 /usr/local/bin/\nfi\n'})}),"\n",(0,s.jsxs)(n.p,{children:["Install ",(0,s.jsx)(n.a,{href:"https://github.com/rakyll/hey",children:"hey"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'if ! command -v hey &> /dev/null; then\n  sudo curl -s -Lo /usr/local/bin/hey "https://hey-release.s3.us-east-2.amazonaws.com/hey_$(uname | sed "s/./\\L&/g")_amd64"\n  sudo chmod a+x /usr/local/bin/hey\nfi\n'})}),"\n",(0,s.jsx)(n.h2,{id:"configure-aws-route-53-domain-delegation",children:"Configure AWS Route 53 Domain delegation"}),"\n",(0,s.jsxs)(n.p,{children:["Create DNS zone (",(0,s.jsx)(n.code,{children:"BASE_DOMAIN"}),"):"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-shell",children:'aws route53 create-hosted-zone --output json \\\n  --name "${BASE_DOMAIN}" \\\n  --caller-reference "$(date)" \\\n  --hosted-zone-config="{\\"Comment\\": \\"Created by ${MY_EMAIL}\\", \\"PrivateZone\\": false}" | jq\n'})}),"\n",(0,s.jsx)(n.p,{children:'Use your domain registrar to change the nameservers for your zone (for example\n"mylabs.dev") to use the Amazon Route 53 nameservers. Here is the way how you\ncan find out the the Route 53 nameservers:'}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-shell",children:'NEW_ZONE_ID=$(aws route53 list-hosted-zones --query "HostedZones[?Name==\\`${BASE_DOMAIN}.\\`].Id" --output text)\nNEW_ZONE_NS=$(aws route53 get-hosted-zone --output json --id "${NEW_ZONE_ID}" --query "DelegationSet.NameServers")\nNEW_ZONE_NS1=$(echo "${NEW_ZONE_NS}" | jq -r ".[0]")\nNEW_ZONE_NS2=$(echo "${NEW_ZONE_NS}" | jq -r ".[1]")\n'})}),"\n",(0,s.jsxs)(n.p,{children:["Create the NS record in ",(0,s.jsx)(n.code,{children:"k8s.mylabs.dev"})," (",(0,s.jsx)(n.code,{children:"BASE_DOMAIN"}),") for proper zone\ndelegation. This step depends on your domain registrar - I'm using CloudFlare\nand using Ansible to automate it:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-shell",children:'ansible -m cloudflare_dns -c local -i "localhost," localhost -a "zone=mylabs.dev record=${BASE_DOMAIN} type=NS value=${NEW_ZONE_NS1} solo=true proxied=no account_email=${CLOUDFLARE_EMAIL} account_api_token=${CLOUDFLARE_API_KEY}"\nansible -m cloudflare_dns -c local -i "localhost," localhost -a "zone=mylabs.dev record=${BASE_DOMAIN} type=NS value=${NEW_ZONE_NS2} solo=false proxied=no account_email=${CLOUDFLARE_EMAIL} account_api_token=${CLOUDFLARE_API_KEY}"\n'})}),"\n",(0,s.jsx)(n.p,{children:"Output:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-text",children:'localhost | CHANGED => {\n    "ansible_facts": {\n        "discovered_interpreter_python": "/usr/bin/python"\n    },\n    "changed": true,\n    "result": {\n        "record": {\n            "content": "ns-885.awsdns-46.net",\n            "created_on": "2020-11-13T06:25:32.18642Z",\n            "id": "dxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxb",\n            "locked": false,\n            "meta": {\n                "auto_added": false,\n                "managed_by_apps": false,\n                "managed_by_argo_tunnel": false,\n                "source": "primary"\n            },\n            "modified_on": "2020-11-13T06:25:32.18642Z",\n            "name": "k8s.mylabs.dev",\n            "proxiable": false,\n            "proxied": false,\n            "ttl": 1,\n            "type": "NS",\n            "zone_id": "2xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxe",\n            "zone_name": "mylabs.dev"\n        }\n    }\n}\nlocalhost | CHANGED => {\n    "ansible_facts": {\n        "discovered_interpreter_python": "/usr/bin/python"\n    },\n    "changed": true,\n    "result": {\n        "record": {\n            "content": "ns-1692.awsdns-19.co.uk",\n            "created_on": "2020-11-13T06:25:37.605605Z",\n            "id": "9xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxb",\n            "locked": false,\n            "meta": {\n                "auto_added": false,\n                "managed_by_apps": false,\n                "managed_by_argo_tunnel": false,\n                "source": "primary"\n            },\n            "modified_on": "2020-11-13T06:25:37.605605Z",\n            "name": "k8s.mylabs.dev",\n            "proxiable": false,\n            "proxied": false,\n            "ttl": 1,\n            "type": "NS",\n            "zone_id": "2xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxe",\n            "zone_name": "mylabs.dev"\n        }\n    }\n}\n'})}),"\n",(0,s.jsx)(n.h2,{id:"add-new-domain-to-route-53-policies-s3-ebs",children:"Add new domain to Route 53, Policies, S3, EBS"}),"\n",(0,s.jsx)(n.p,{children:"Details with examples are described on these links:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://aws.amazon.com/blogs/opensource/introducing-fine-grained-iam-roles-service-accounts/",children:"https://aws.amazon.com/blogs/opensource/introducing-fine-grained-iam-roles-service-accounts/"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://cert-manager.io/docs/configuration/acme/dns01/route53/",children:"https://cert-manager.io/docs/configuration/acme/dns01/route53/"})}),"\n",(0,s.jsx)(n.li,{children:(0,s.jsx)(n.a,{href:"https://github.com/kubernetes-sigs/external-dns/blob/master/docs/tutorials/aws.md",children:"https://github.com/kubernetes-sigs/external-dns/blob/master/docs/tutorials/aws.md"})}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["Create CloudFormation template containing policies for Route53, S3 access\n(Harbor, Velero) and Domain. Put new domain ",(0,s.jsx)(n.code,{children:"CLUSTER_FQDN"})," to the Route 53 and\nconfigure the DNS delegation from the ",(0,s.jsx)(n.code,{children:"BASE_DOMAIN"}),"."]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'mkdir -vp "tmp/${CLUSTER_FQDN}"\n\ncat > "tmp/${CLUSTER_FQDN}/aws-route53-iam-s3-kms-asm.yml" << \\EOF\nDescription: "Template to generate the necessary IAM Policies for access to Route53 and S3"\nParameters:\n  ClusterFQDN:\n    Description: "Cluster domain where all necessary app subdomains will live (subdomain of BaseDomain). Ex: kube1.k8s.mylabs.dev"\n    Type: String\n  ClusterName:\n    Description: "Cluster Name Ex: kube1"\n    Type: String\n  BaseDomain:\n    Description: "Base domain where cluster domains + their subdomains will live. Ex: k8s.mylabs.dev"\n    Type: String\nResources:\n  # This AWS control checks whether the status of the AWS Systems Manager association compliance is COMPLIANT or NON_COMPLIANT after the association is executed on an instance.\n  ConfigRule:\n    Type: "AWS::Config::ConfigRule"\n    Properties:\n      ConfigRuleName: !Sub "${ClusterName}-ec2-managedinstance-association-compliance-status-check"\n      Scope:\n        ComplianceResourceTypes:\n          - "AWS::SSM::AssociationCompliance"\n      Description: "A Config rule that checks whether the compliance status of the Amazon EC2 Systems Manager association compliance is COMPLIANT or NON_COMPLIANT after the association execution on the instance. The rule is compliant if the field status is COMPLIANT."\n      Source:\n        Owner: "AWS"\n        SourceIdentifier: "EC2_MANAGEDINSTANCE_ASSOCIATION_COMPLIANCE_STATUS_CHECK"\n  CloudWatchPolicy:\n    Type: AWS::IAM::ManagedPolicy\n    Properties:\n      ManagedPolicyName: !Sub "${ClusterFQDN}-CloudWatch"\n      Description: !Sub "Policy required by Fargate to log to CloudWatch for ${ClusterFQDN}"\n      PolicyDocument:\n        Version: "2012-10-17"\n        Statement:\n        - Effect: Allow\n          Action:\n          - logs:CreateLogStream\n          - logs:CreateLogGroup\n          - logs:DescribeLogStreams\n          - logs:PutLogEvents\n          Resource: "*"\n  HostedZone:\n    Type: AWS::Route53::HostedZone\n    Properties:\n      Name: !Ref ClusterFQDN\n  KMSAlias:\n    Type: AWS::KMS::Alias\n    Properties:\n      AliasName: !Sub "alias/eks-${ClusterName}"\n      TargetKeyId: !Ref KMSKey\n  KMSKey:\n    Type: AWS::KMS::Key\n    Properties:\n      Description: !Sub "KMS key for secrets related to ${ClusterFQDN}"\n      EnableKeyRotation: true\n      PendingWindowInDays: 7\n      KeyPolicy:\n        Version: "2012-10-17"\n        Id: !Sub "eks-key-policy-${ClusterName}"\n        Statement:\n        - Sid: Enable IAM User Permissions\n          Effect: Allow\n          Principal:\n            AWS: !Sub "arn:aws:iam::${AWS::AccountId}:root"\n          Action: kms:*\n          Resource: "*"\n        - Sid: Allow use of the key\n          Effect: Allow\n          Principal:\n            AWS: !Sub "arn:aws:iam::${AWS::AccountId}:role/aws-service-role/autoscaling.amazonaws.com/AWSServiceRoleForAutoScaling"\n          Action:\n          - kms:Encrypt\n          - kms:Decrypt\n          - kms:ReEncrypt*\n          - kms:GenerateDataKey*\n          - kms:DescribeKey\n          Resource: "*"\n        - Sid: Allow attachment of persistent resources\n          Effect: Allow\n          Principal:\n            AWS: !Sub "arn:aws:iam::${AWS::AccountId}:role/aws-service-role/autoscaling.amazonaws.com/AWSServiceRoleForAutoScaling"\n          Action:\n          - kms:CreateGrant\n          Resource: "*"\n          Condition:\n            Bool:\n              kms:GrantIsForAWSResource: true\n  EKSViewNodesAndWorkloadsPolicy:\n    Type: AWS::IAM::ManagedPolicy\n    Properties:\n      ManagedPolicyName: !Sub "${ClusterFQDN}-EKSViewNodesAndWorkloads"\n      Description: !Sub "Policy used to view workloads running in an EKS cluster created using CAPA"\n      PolicyDocument:\n        Version: "2012-10-17"\n        Statement:\n        - Effect: Allow\n          Action:\n          - eks:DescribeNodegroup\n          - eks:ListNodegroups\n          - eks:DescribeCluster\n          - eks:ListClusters\n          - eks:AccessKubernetesApi\n          - ssm:GetParameter\n          - eks:ListUpdates\n          - eks:ListFargateProfiles\n          Resource: "*"\n  RecordSet:\n    Type: AWS::Route53::RecordSet\n    Properties:\n      HostedZoneName: !Sub "${BaseDomain}."\n      Name: !Ref ClusterFQDN\n      Type: NS\n      TTL: 60\n      ResourceRecords: !GetAtt HostedZone.NameServers\n  S3Policy:\n    Type: AWS::IAM::ManagedPolicy\n    Properties:\n      ManagedPolicyName: !Sub "${ClusterFQDN}-AmazonS3"\n      Description: !Sub "Policy required by Harbor and Velero to write to S3 bucket ${ClusterFQDN}"\n      PolicyDocument:\n        Version: "2012-10-17"\n        Statement:\n        - Effect: Allow\n          Action:\n          - s3:ListBucket\n          - s3:GetBucketLocation\n          - s3:ListBucketMultipartUploads\n          Resource: !GetAtt S3Bucket.Arn\n        - Effect: Allow\n          Action:\n          - s3:PutObject\n          - s3:GetObject\n          - s3:DeleteObject\n          - s3:ListMultipartUploadParts\n          - s3:AbortMultipartUpload\n          Resource: !Sub "arn:aws:s3:::${ClusterFQDN}/*"\n  S3Bucket:\n    Type: AWS::S3::Bucket\n    Properties:\n      AccessControl: Private\n      BucketName: !Sub "${ClusterFQDN}"\n      BucketEncryption:\n        ServerSideEncryptionConfiguration:\n          - ServerSideEncryptionByDefault:\n              SSEAlgorithm: AES256\n  SecretsManagerMySecret:\n    Type: AWS::SecretsManager::Secret\n    Properties:\n      Name: !Sub "${ClusterFQDN}-MySecret"\n      Description: My Secret\n      GenerateSecretString:\n        SecretStringTemplate: "{\\"username\\": \\"Administrator\\"}"\n        GenerateStringKey: password\n        PasswordLength: 32\n      KmsKeyId: !Ref KMSKey\n  SecretsManagerMySecret2:\n    Type: AWS::SecretsManager::Secret\n    Properties:\n      Name: !Sub "${ClusterFQDN}-MySecret2"\n      Description: My Secret2\n      GenerateSecretString:\n        SecretStringTemplate: "{\\"username\\": \\"Administrator2\\"}"\n        GenerateStringKey: password\n        PasswordLength: 32\n      KmsKeyId: !Ref KMSKey\n  UserMyUser1:\n    Type: AWS::IAM::User\n    Properties:\n      UserName: !Sub "myuser1-${ClusterName}"\n      Policies:\n      - PolicyName: !Sub "myuser1-${ClusterName}-policy"\n        PolicyDocument:\n          Version: "2012-10-17"\n          Statement:\n          - Sid: AllowAssumeOrganizationAccountRole\n            Effect: Allow\n            Action: sts:AssumeRole\n            Resource: !GetAtt RoleMyUser1.Arn\n  AccessKeyMyUser1:\n    Type: AWS::IAM::AccessKey\n    Properties:\n      UserName: !Ref UserMyUser1\n  RoleMyUser1:\n    Type: AWS::IAM::Role\n    Properties:\n      Description: !Sub "IAM role for the myuser1-${ClusterName} user"\n      RoleName: !Sub "myuser1-${ClusterName}"\n      AssumeRolePolicyDocument:\n        Version: 2012-10-17\n        Statement:\n        - Effect: Allow\n          Principal:\n            AWS: !Sub "arn:aws:iam::${AWS::AccountId}:root"\n          Action: sts:AssumeRole\n  UserMyUser2:\n    Type: AWS::IAM::User\n    Properties:\n      UserName: !Sub "myuser2-${ClusterName}"\n      Policies:\n      - PolicyName: !Sub "myuser2-${ClusterName}-policy"\n        PolicyDocument:\n          Version: "2012-10-17"\n          Statement:\n          - Sid: AllowAssumeOrganizationAccountRole\n            Effect: Allow\n            Action: sts:AssumeRole\n            Resource: !GetAtt RoleMyUser2.Arn\n  AccessKeyMyUser2:\n    Type: AWS::IAM::AccessKey\n    Properties:\n      UserName: !Ref UserMyUser2\n  RoleMyUser2:\n    Type: AWS::IAM::Role\n    Properties:\n      Description: !Sub "IAM role for the myuser2-${ClusterName} user"\n      RoleName: !Sub "myuser2-${ClusterName}"\n      AssumeRolePolicyDocument:\n        Version: 2012-10-17\n        Statement:\n        - Effect: Allow\n          Principal:\n            AWS: !Sub "arn:aws:iam::${AWS::AccountId}:root"\n          Action: sts:AssumeRole\nOutputs:\n  CloudWatchPolicyArn:\n    Description: The ARN of the created CloudWatchPolicy\n    Value: !Ref CloudWatchPolicy\n    Export:\n      Name:\n        Fn::Sub: "${AWS::StackName}-CloudWatchPolicyArn"\n  KMSKeyArn:\n    Description: The ARN of the created KMS Key to encrypt EKS related services\n    Value: !GetAtt KMSKey.Arn\n    Export:\n      Name:\n        Fn::Sub: "${AWS::StackName}-KMSKeyArn"\n  KMSKeyId:\n    Description: The ID of the created KMS Key to encrypt EKS related services\n    Value: !Ref KMSKey\n    Export:\n      Name:\n        Fn::Sub: "${AWS::StackName}-KMSKeyId"\n  HostedZoneArn:\n    Description: The ARN of the created Route53 Zone for K8s cluster\n    Value: !Ref HostedZone\n    Export:\n      Name:\n        Fn::Sub: "${AWS::StackName}-HostedZoneArn"\n  S3PolicyArn:\n    Description: The ARN of the created AmazonS3 policy\n    Value: !Ref S3Policy\n    Export:\n      Name:\n        Fn::Sub: "${AWS::StackName}-S3PolicyArn"\n  RoleMyUser1Arn:\n    Description: The ARN of the MyUser1 IAM Role\n    Value: !GetAtt RoleMyUser1.Arn\n    Export:\n      Name:\n        Fn::Sub: "${AWS::StackName}-RoleMyUser1Arn"\n  AccessKeyMyUser1:\n    Description: The AccessKey for MyUser1 user\n    Value: !Ref AccessKeyMyUser1\n    Export:\n      Name:\n        Fn::Sub: "${AWS::StackName}-AccessKeyMyUser1"\n  SecretAccessKeyMyUser1:\n    Description: The SecretAccessKey for MyUser1 user\n    Value: !GetAtt AccessKeyMyUser1.SecretAccessKey\n    Export:\n      Name:\n        Fn::Sub: "${AWS::StackName}-SecretAccessKeyMyUser1"\n  RoleMyUser2Arn:\n    Description: The ARN of the MyUser2 IAM Role\n    Value: !GetAtt RoleMyUser2.Arn\n    Export:\n      Name:\n        Fn::Sub: "${AWS::StackName}-RoleMyUser2Arn"\n  AccessKeyMyUser2:\n    Description: The AccessKey for MyUser2 user\n    Value: !Ref AccessKeyMyUser2\n    Export:\n      Name:\n        Fn::Sub: "${AWS::StackName}-AccessKeyMyUser2"\n  SecretAccessKeyMyUser2:\n    Description: The SecretAccessKey for MyUser2 user\n    Value: !GetAtt AccessKeyMyUser2.SecretAccessKey\n    Export:\n      Name:\n        Fn::Sub: "${AWS::StackName}-SecretAccessKeyMyUser2"\nEOF\n\neval aws cloudformation deploy --capabilities CAPABILITY_NAMED_IAM \\\n  --parameter-overrides "ClusterFQDN=${CLUSTER_FQDN} ClusterName=${CLUSTER_NAME} BaseDomain=${BASE_DOMAIN}" \\\n  --stack-name "${CLUSTER_NAME}-route53-iam-s3-kms-asm" --template-file "tmp/${CLUSTER_FQDN}/aws-route53-iam-s3-kms-asm.yml" --tags "${TAGS}"\n\nAWS_CLOUDFORMATION_DETAILS=$(aws cloudformation describe-stacks --stack-name "${CLUSTER_NAME}-route53-iam-s3-kms-asm")\n# CLOUDWATCH_POLICY_ARN=$(echo "${AWS_CLOUDFORMATION_DETAILS}" | jq -r ".Stacks[0].Outputs[] | select(.OutputKey==\\"CloudWatchPolicyArn\\") .OutputValue")\nKMS_KEY_ARN=$(echo "${AWS_CLOUDFORMATION_DETAILS}" | jq -r ".Stacks[0].Outputs[] | select(.OutputKey==\\"KMSKeyArn\\") .OutputValue")\nKMS_KEY_ID=$(echo "${AWS_CLOUDFORMATION_DETAILS}" | jq -r ".Stacks[0].Outputs[] | select(.OutputKey==\\"KMSKeyId\\") .OutputValue")\nS3_POLICY_ARN=$(echo "${AWS_CLOUDFORMATION_DETAILS}" | jq -r ".Stacks[0].Outputs[] | select(.OutputKey==\\"S3PolicyArn\\") .OutputValue")\n# MYUSER1_ROLE_ARN=$(echo "${AWS_CLOUDFORMATION_DETAILS}" | jq -r ".Stacks[0].Outputs[] | select(.OutputKey==\\"RoleMyUser1Arn\\") .OutputValue")\n# MYUSER1_USER_ACCESSKEYMYUSER=$(echo "${AWS_CLOUDFORMATION_DETAILS}" | jq -r ".Stacks[0].Outputs[] | select(.OutputKey==\\"AccessKeyMyUser1\\") .OutputValue")\n# MYUSER1_USER_SECRETACCESSKEY=$(echo "${AWS_CLOUDFORMATION_DETAILS}" | jq -r ".Stacks[0].Outputs[] | select(.OutputKey==\\"SecretAccessKeyMyUser1\\") .OutputValue")\n# MYUSER2_ROLE_ARN=$(echo "${AWS_CLOUDFORMATION_DETAILS}" | jq -r ".Stacks[0].Outputs[] | select(.OutputKey==\\"RoleMyUser2Arn\\") .OutputValue")\n# MYUSER2_USER_ACCESSKEYMYUSER=$(echo "${AWS_CLOUDFORMATION_DETAILS}" | jq -r ".Stacks[0].Outputs[] | select(.OutputKey==\\"AccessKeyMyUser2\\") .OutputValue")\n# MYUSER2_USER_SECRETACCESSKEY=$(echo "${AWS_CLOUDFORMATION_DETAILS}" | jq -r ".Stacks[0].Outputs[] | select(.OutputKey==\\"SecretAccessKeyMyUser2\\") .OutputValue")\n'})}),"\n",(0,s.jsx)(n.p,{children:"Change TTL=60 of SOA + NS records for new domain\n(it can not be done in CloudFormation):"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'HOSTED_ZONE_ID=$(aws route53 list-hosted-zones --query "HostedZones[?Name==\\`${CLUSTER_FQDN}.\\`].Id" --output text)\nRESOURCE_RECORD_SET_SOA=$(aws route53 --output json list-resource-record-sets --hosted-zone-id "${HOSTED_ZONE_ID}" --query "(ResourceRecordSets[?Type == \\`SOA\\`])[0]" | sed "s/\\"TTL\\":.*/\\"TTL\\": 60,/")\nRESOURCE_RECORD_SET_NS=$(aws route53 --output json list-resource-record-sets --hosted-zone-id "${HOSTED_ZONE_ID}" --query "(ResourceRecordSets[?Type == \\`NS\\`])[0]" | sed "s/\\"TTL\\":.*/\\"TTL\\": 60,/")\ncat << EOF | aws route53 --output json change-resource-record-sets --hosted-zone-id "${HOSTED_ZONE_ID}" --change-batch=file:///dev/stdin\n{\n    "Comment": "Update record to reflect new TTL for SOA and NS records",\n    "Changes": [\n        {\n            "Action": "UPSERT",\n            "ResourceRecordSet":\n${RESOURCE_RECORD_SET_SOA}\n        },\n        {\n            "Action": "UPSERT",\n            "ResourceRecordSet":\n${RESOURCE_RECORD_SET_NS}\n        }\n    ]\n}\nEOF\n'})}),"\n",(0,s.jsx)(n.h2,{id:"create-amazon-eks",children:"Create Amazon EKS"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{src:"https://raw.githubusercontent.com/aws-samples/eks-workshop/65b766c494a5b4f5420b2912d8373c4957163541/static/images/3-service-animated.gif",alt:"EKS",title:"EKS"})}),"\n",(0,s.jsxs)(n.p,{children:["Create ",(0,s.jsx)(n.a,{href:"https://aws.amazon.com/eks/",children:"Amazon EKS"})," in AWS by using ",(0,s.jsx)(n.a,{href:"https://eksctl.io/",children:"eksctl"}),".\nIt's a tool from Weaveworks based on official\nAWS CloudFormation templates which will be used to launch and configure our\nEKS cluster and nodes."]}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{src:"https://raw.githubusercontent.com/weaveworks/eksctl/c365149fc1a0b8d357139cbd6cda5aee8841c16c/logo/eksctl.png",alt:"eksctl",title:"eksctl"})}),"\n",(0,s.jsx)(n.p,{children:"Generate SSH key if not exists:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'test -f ~/.ssh/id_rsa.pub || (install -m 0700 -d ~/.ssh && ssh-keygen -b 2048 -t rsa -f ~/.ssh/id_rsa -q -N "")\n'})}),"\n",(0,s.jsxs)(n.p,{children:["Create the Amazon EKS cluster with Calico using ",(0,s.jsx)(n.code,{children:"eksctl"}),":"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'cat > "tmp/${CLUSTER_FQDN}/eksctl.yaml" << EOF\napiVersion: eksctl.io/v1alpha5\nkind: ClusterConfig\nmetadata:\n  name: ${CLUSTER_NAME}\n  region: ${AWS_DEFAULT_REGION}\n  version: "1.21"\n  tags: &tags\n$(echo "${TAGS}" | sed "s/ /\\\\n    /g; s/^/    /g; s/=/: /g")\navailabilityZones:\n  - ${AWS_DEFAULT_REGION}a\n  - ${AWS_DEFAULT_REGION}b\niam:\n  withOIDC: true\n  serviceAccounts:\n    - metadata:\n        name: aws-load-balancer-controller\n        namespace: kube-system\n      wellKnownPolicies:\n        awsLoadBalancerController: true\n    - metadata:\n        name: cert-manager\n        namespace: cert-manager\n      wellKnownPolicies:\n        certManager: true\n    - metadata:\n        name: cluster-autoscaler\n        namespace: kube-system\n      wellKnownPolicies:\n        autoScaler: true\n    - metadata:\n        name: external-dns\n        namespace: external-dns\n      wellKnownPolicies:\n        externalDNS: true\n    - metadata:\n        name: ebs-csi-controller-sa\n        namespace: kube-system\n      wellKnownPolicies:\n        ebsCSIController: true\n    - metadata:\n        name: harbor\n        namespace: harbor\n      attachPolicyARNs:\n        - ${S3_POLICY_ARN}\n    - metadata:\n        name: velero\n        namespace: velero\n      attachPolicyARNs:\n        - ${S3_POLICY_ARN}\n    - metadata:\n        name: s3-test\n        namespace: s3-test\n      attachPolicyARNs:\n        - ${S3_POLICY_ARN}\n    - metadata:\n        name: grafana\n        namespace: kube-prometheus-stack\n      attachPolicyARNs:\n        - arn:aws:iam::aws:policy/AmazonPrometheusQueryAccess\n        - arn:aws:iam::aws:policy/CloudWatchReadOnlyAccess\n      attachPolicy:\n        Version: 2012-10-17\n        Statement:\n        - Sid: AllowReadingTagsInstancesRegionsFromEC2\n          Effect: Allow\n          Action:\n          - ec2:DescribeTags\n          - ec2:DescribeInstances\n          - ec2:DescribeRegions\n          Resource: "*"\n        - Sid: AllowReadingResourcesForTags\n          Effect: Allow\n          Action: tag:GetResources\n          Resource: "*"\n    - metadata:\n        name: kube-prometheus-stack-prometheus\n        namespace: kube-prometheus-stack\n      attachPolicyARNs:\n        - arn:aws:iam::aws:policy/AmazonPrometheusQueryAccess\n        - arn:aws:iam::aws:policy/AmazonPrometheusRemoteWriteAccess\n    - metadata:\n        name: efs-csi-controller-sa\n        namespace: kube-system\n      wellKnownPolicies:\n        efsCSIController: true\n    - metadata:\n        name: vault\n        namespace: vault\n      attachPolicy:\n        Version: 2012-10-17\n        Statement:\n        - Sid: VaultKMSUnseal\n          Effect: Allow\n          Action:\n          - kms:Encrypt\n          - kms:Decrypt\n          - kms:DescribeKey\n          Resource:\n          - "${KMS_KEY_ARN}"\n    - metadata:\n        name: kuard\n        namespace: kuard\n      attachPolicy:\n        Version: 2012-10-17\n        Statement:\n        - Sid: AllowSecretManagerAccess\n          Effect: Allow\n          Action:\n          - secretsmanager:GetSecretValue\n          - secretsmanager:DescribeSecret\n          Resource:\n          - "arn:aws:secretsmanager:*:*:secret:*"\n        - Sid: AllowKMSAccess\n          Effect: Allow\n          Action:\n          - kms:Decrypt\n          Resource:\n          - "${KMS_KEY_ARN}"\nvpc:\n  nat:\n    gateway: Disable\nmanagedNodeGroups:\n  - name: managed-ng-1\n    amiFamily: Bottlerocket\n    instanceType: t3.xlarge\n    instancePrefix: ruzickap\n    desiredCapacity: 3\n    minSize: 2\n    maxSize: 5\n    volumeSize: 30\n    labels:\n      role: worker\n    tags: *tags\n    iam:\n      withAddonPolicies:\n        autoScaler: true\n        cloudWatch: true\n        ebs: true\n        efs: true\n    maxPodsPerNode: 1000\n    volumeEncrypted: true\n    volumeKmsKeyID: ${KMS_KEY_ID}\nfargateProfiles:\n  - name: fp-fgtest\n    selectors:\n      - namespace: fgtest\n    tags: *tags\nsecretsEncryption:\n  keyARN: ${KMS_KEY_ARN}\ncloudWatch:\n  clusterLogging:\n    enableTypes:\n      - authenticator\nEOF\n\nif ! eksctl get clusters --name="${CLUSTER_NAME}" &> /dev/null; then\n  eksctl create cluster --config-file "tmp/${CLUSTER_FQDN}/eksctl.yaml" --kubeconfig "${KUBECONFIG}" --without-nodegroup\n  kubectl delete daemonset -n kube-system aws-node\n  kubectl apply -f https://docs.projectcalico.org/archive/v3.20/manifests/calico-vxlan.yaml\n  eksctl create nodegroup --config-file "tmp/${CLUSTER_FQDN}/eksctl.yaml"\nfi\n'})}),"\n",(0,s.jsx)(n.p,{children:"Output:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-text",children:'2021-11-29 17:52:50 [\u2139]  eksctl version 0.75.0\n2021-11-29 17:52:50 [\u2139]  using region eu-west-1\n2021-11-29 17:52:50 [\u2139]  subnets for eu-west-1a - public:192.168.0.0/19 private:192.168.64.0/19\n2021-11-29 17:52:50 [\u2139]  subnets for eu-west-1b - public:192.168.32.0/19 private:192.168.96.0/19\n2021-11-29 17:52:50 [\u2139]  using Kubernetes version 1.21\n2021-11-29 17:52:50 [\u2139]  creating EKS cluster "kube1" in "eu-west-1" region with Fargate profile\n2021-11-29 17:52:50 [\u2139]  will create a CloudFormation stack for cluster itself and 0 nodegroup stack(s)\n2021-11-29 17:52:50 [\u2139]  will create a CloudFormation stack for cluster itself and 0 managed nodegroup stack(s)\n2021-11-29 17:52:50 [\u2139]  if you encounter any issues, check CloudFormation console or try \'eksctl utils describe-stacks --region=eu-west-1 --cluster=kube1\'\n2021-11-29 17:52:50 [\u2139]  Kubernetes API endpoint access will use default of {publicAccess=true, privateAccess=false} for cluster "kube1" in "eu-west-1"\n2021-11-29 17:52:50 [\u2139]\n2 sequential tasks: { create cluster control plane "kube1",\n    7 sequential sub-tasks: {\n        wait for control plane to become ready,\n        tag cluster,\n        update CloudWatch logging configuration,\n        create fargate profiles,\n        associate IAM OIDC provider,\n        14 parallel sub-tasks: {\n            2 sequential sub-tasks: {\n                create IAM role for serviceaccount "kube-system/aws-load-balancer-controller",\n                create serviceaccount "kube-system/aws-load-balancer-controller",\n            },\n            2 sequential sub-tasks: {\n                create IAM role for serviceaccount "cert-manager/cert-manager",\n                create serviceaccount "cert-manager/cert-manager",\n            },\n            2 sequential sub-tasks: {\n                create IAM role for serviceaccount "kube-system/cluster-autoscaler",\n                create serviceaccount "kube-system/cluster-autoscaler",\n            },\n            2 sequential sub-tasks: {\n                create IAM role for serviceaccount "external-dns/external-dns",\n                create serviceaccount "external-dns/external-dns",\n            },\n            2 sequential sub-tasks: {\n                create IAM role for serviceaccount "kube-system/ebs-csi-controller-sa",\n                create serviceaccount "kube-system/ebs-csi-controller-sa",\n            },\n            2 sequential sub-tasks: {\n                create IAM role for serviceaccount "harbor/harbor",\n                create serviceaccount "harbor/harbor",\n            },\n            2 sequential sub-tasks: {\n                create IAM role for serviceaccount "velero/velero",\n                create serviceaccount "velero/velero",\n            },\n            2 sequential sub-tasks: {\n                create IAM role for serviceaccount "s3-test/s3-test",\n                create serviceaccount "s3-test/s3-test",\n            },\n            2 sequential sub-tasks: {\n                create IAM role for serviceaccount "kube-prometheus-stack/grafana",\n                create serviceaccount "kube-prometheus-stack/grafana",\n            },\n            2 sequential sub-tasks: {\n                create IAM role for serviceaccount "kube-prometheus-stack/kube-prometheus-stack-prometheus",\n                create serviceaccount "kube-prometheus-stack/kube-prometheus-stack-prometheus",\n            },\n            2 sequential sub-tasks: {\n                create IAM role for serviceaccount "kube-system/efs-csi-controller-sa",\n                create serviceaccount "kube-system/efs-csi-controller-sa",\n            },\n            2 sequential sub-tasks: {\n                create IAM role for serviceaccount "vault/vault",\n                create serviceaccount "vault/vault",\n            },\n            2 sequential sub-tasks: {\n                create IAM role for serviceaccount "kuard/kuard",\n                create serviceaccount "kuard/kuard",\n            },\n            2 sequential sub-tasks: {\n                create IAM role for serviceaccount "kube-system/aws-node",\n                create serviceaccount "kube-system/aws-node",\n            },\n        },\n        restart daemonset "kube-system/aws-node",\n    }\n}\n2021-11-29 17:52:50 [\u2139]  building cluster stack "eksctl-kube1-cluster"\n2021-11-29 17:52:50 [\u2139]  deploying stack "eksctl-kube1-cluster"\n2021-11-29 17:53:21 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-cluster"\n...\n2021-11-29 18:05:55 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-cluster"\n2021-11-29 18:07:59 [\u2714]  tagged EKS cluster (Owner=petr.ruzicka@gmail.com, Squad=Cloud_Container_Platform, compliance:na:defender=bottlerocket, Environment=Dev, Group=Cloud_Native)\n2021-11-29 18:08:00 [\u2139]  waiting for requested "LoggingUpdate" in cluster "kube1" to succeed\n...\n2021-11-29 18:08:53 [\u2139]  waiting for requested "LoggingUpdate" in cluster "kube1" to succeed\n2021-11-29 18:08:54 [\u2714]  configured CloudWatch logging for cluster "kube1" in "eu-west-1" (enabled types: authenticator & disabled types: api, audit, controllerManager, scheduler)\n2021-11-29 18:08:54 [\u2139]  creating Fargate profile "fp-fgtest" on EKS cluster "kube1"\n2021-11-29 18:13:12 [\u2139]  created Fargate profile "fp-fgtest" on EKS cluster "kube1"\n2021-11-29 18:17:44 [\u2139]  building iamserviceaccount stack "eksctl-kube1-addon-iamserviceaccount-kube-system-aws-load-balancer-controller"\n2021-11-29 18:17:44 [\u2139]  building iamserviceaccount stack "eksctl-kube1-addon-iamserviceaccount-kube-prometheus-stack-grafana"\n2021-11-29 18:17:44 [\u2139]  building iamserviceaccount stack "eksctl-kube1-addon-iamserviceaccount-velero-velero"\n2021-11-29 18:17:44 [\u2139]  building iamserviceaccount stack "eksctl-kube1-addon-iamserviceaccount-kube-system-efs-csi-controller-sa"\n2021-11-29 18:17:44 [\u2139]  building iamserviceaccount stack "eksctl-kube1-addon-iamserviceaccount-kuard-kuard"\n2021-11-29 18:17:44 [\u2139]  building iamserviceaccount stack "eksctl-kube1-addon-iamserviceaccount-cert-manager-cert-manager"\n2021-11-29 18:17:44 [\u2139]  building iamserviceaccount stack "eksctl-kube1-addon-iamserviceaccount-kube-system-aws-node"\n2021-11-29 18:17:44 [\u2139]  building iamserviceaccount stack "eksctl-kube1-addon-iamserviceaccount-kube-system-ebs-csi-controller-sa"\n2021-11-29 18:17:44 [\u2139]  building iamserviceaccount stack "eksctl-kube1-addon-iamserviceaccount-kube-system-cluster-autoscaler"\n2021-11-29 18:17:44 [\u2139]  building iamserviceaccount stack "eksctl-kube1-addon-iamserviceaccount-kube-prometheus-stack-kube-prometheus-stack-prometheus"\n2021-11-29 18:17:44 [\u2139]  building iamserviceaccount stack "eksctl-kube1-addon-iamserviceaccount-external-dns-external-dns"\n2021-11-29 18:17:44 [\u2139]  building iamserviceaccount stack "eksctl-kube1-addon-iamserviceaccount-s3-test-s3-test"\n2021-11-29 18:17:44 [\u2139]  building iamserviceaccount stack "eksctl-kube1-addon-iamserviceaccount-vault-vault"\n2021-11-29 18:17:44 [\u2139]  building iamserviceaccount stack "eksctl-kube1-addon-iamserviceaccount-harbor-harbor"\n2021-11-29 18:17:45 [\u2139]  deploying stack "eksctl-kube1-addon-iamserviceaccount-kube-system-cluster-autoscaler"\n2021-11-29 18:17:45 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-kube-system-cluster-autoscaler"\n2021-11-29 18:17:45 [\u2139]  deploying stack "eksctl-kube1-addon-iamserviceaccount-harbor-harbor"\n2021-11-29 18:17:45 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-harbor-harbor"\n2021-11-29 18:17:45 [\u2139]  deploying stack "eksctl-kube1-addon-iamserviceaccount-kube-prometheus-stack-grafana"\n2021-11-29 18:17:45 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-kube-prometheus-stack-grafana"\n2021-11-29 18:17:45 [\u2139]  deploying stack "eksctl-kube1-addon-iamserviceaccount-s3-test-s3-test"\n2021-11-29 18:17:45 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-s3-test-s3-test"\n2021-11-29 18:17:45 [\u2139]  deploying stack "eksctl-kube1-addon-iamserviceaccount-cert-manager-cert-manager"\n2021-11-29 18:17:45 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-cert-manager-cert-manager"\n2021-11-29 18:17:45 [\u2139]  deploying stack "eksctl-kube1-addon-iamserviceaccount-kube-system-efs-csi-controller-sa"\n2021-11-29 18:17:45 [\u2139]  deploying stack "eksctl-kube1-addon-iamserviceaccount-vault-vault"\n2021-11-29 18:17:45 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-kube-system-efs-csi-controller-sa"\n2021-11-29 18:17:45 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-vault-vault"\n2021-11-29 18:17:45 [\u2139]  deploying stack "eksctl-kube1-addon-iamserviceaccount-velero-velero"\n2021-11-29 18:17:45 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-velero-velero"\n2021-11-29 18:17:45 [\u2139]  deploying stack "eksctl-kube1-addon-iamserviceaccount-kuard-kuard"\n2021-11-29 18:17:45 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-kuard-kuard"\n2021-11-29 18:17:45 [\u2139]  deploying stack "eksctl-kube1-addon-iamserviceaccount-external-dns-external-dns"\n2021-11-29 18:17:45 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-external-dns-external-dns"\n2021-11-29 18:17:45 [\u2139]  deploying stack "eksctl-kube1-addon-iamserviceaccount-kube-prometheus-stack-kube-prometheus-stack-prometheus"\n2021-11-29 18:17:45 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-kube-prometheus-stack-kube-prometheus-stack-prometheus"\n2021-11-29 18:17:45 [\u2139]  deploying stack "eksctl-kube1-addon-iamserviceaccount-kube-system-aws-node"\n2021-11-29 18:17:45 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-kube-system-aws-node"\n2021-11-29 18:17:45 [\u2139]  deploying stack "eksctl-kube1-addon-iamserviceaccount-kube-system-aws-load-balancer-controller"\n2021-11-29 18:17:45 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-kube-system-aws-load-balancer-controller"\n2021-11-29 18:17:45 [\u2139]  deploying stack "eksctl-kube1-addon-iamserviceaccount-kube-system-ebs-csi-controller-sa"\n2021-11-29 18:17:45 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-kube-system-ebs-csi-controller-sa"\n2021-11-29 18:18:00 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-kube-system-cluster-autoscaler"\n2021-11-29 18:18:00 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-kube-prometheus-stack-grafana"\n2021-11-29 18:18:01 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-velero-velero"\n2021-11-29 18:18:02 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-kube-system-aws-load-balancer-controller"\n2021-11-29 18:18:02 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-harbor-harbor"\n2021-11-29 18:18:02 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-s3-test-s3-test"\n2021-11-29 18:18:02 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-kube-system-ebs-csi-controller-sa"\n2021-11-29 18:18:03 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-cert-manager-cert-manager"\n2021-11-29 18:18:03 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-vault-vault"\n2021-11-29 18:18:03 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-kuard-kuard"\n2021-11-29 18:18:04 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-kube-system-efs-csi-controller-sa"\n2021-11-29 18:18:04 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-kube-system-aws-node"\n2021-11-29 18:18:04 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-kube-prometheus-stack-kube-prometheus-stack-prometheus"\n2021-11-29 18:18:05 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-external-dns-external-dns"\n2021-11-29 18:18:17 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-harbor-harbor"\n2021-11-29 18:18:18 [\u2139]  created namespace "harbor"\n2021-11-29 18:18:18 [\u2139]  created serviceaccount "harbor/harbor"\n2021-11-29 18:18:18 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-s3-test-s3-test"\n2021-11-29 18:18:18 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-kube-system-cluster-autoscaler"\n2021-11-29 18:18:18 [\u2139]  created namespace "s3-test"\n2021-11-29 18:18:18 [\u2139]  created serviceaccount "s3-test/s3-test"\n2021-11-29 18:18:19 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-velero-velero"\n2021-11-29 18:18:19 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-cert-manager-cert-manager"\n2021-11-29 18:18:19 [\u2139]  created namespace "velero"\n2021-11-29 18:18:19 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-kube-system-aws-load-balancer-controller"\n2021-11-29 18:18:20 [\u2139]  created serviceaccount "velero/velero"\n2021-11-29 18:18:20 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-vault-vault"\n2021-11-29 18:18:20 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-kube-prometheus-stack-grafana"\n2021-11-29 18:18:21 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-kube-prometheus-stack-kube-prometheus-stack-prometheus"\n2021-11-29 18:18:21 [\u2139]  created namespace "kube-prometheus-stack"\n2021-11-29 18:18:21 [\u2139]  created serviceaccount "kube-prometheus-stack/kube-prometheus-stack-prometheus"\n2021-11-29 18:18:21 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-kube-system-ebs-csi-controller-sa"\n2021-11-29 18:18:21 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-kuard-kuard"\n2021-11-29 18:18:24 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-kube-system-efs-csi-controller-sa"\n2021-11-29 18:18:24 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-external-dns-external-dns"\n2021-11-29 18:18:24 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-kube-system-aws-node"\n2021-11-29 18:18:24 [\u2139]  serviceaccount "kube-system/aws-node" already exists\n2021-11-29 18:18:24 [\u2139]  updated serviceaccount "kube-system/aws-node"\n2021-11-29 18:18:35 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-kube-system-cluster-autoscaler"\n2021-11-29 18:18:36 [\u2139]  created serviceaccount "kube-system/cluster-autoscaler"\n2021-11-29 18:18:37 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-kube-prometheus-stack-grafana"\n2021-11-29 18:18:38 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-kuard-kuard"\n2021-11-29 18:18:38 [\u2139]  created serviceaccount "kube-prometheus-stack/grafana"\n2021-11-29 18:18:38 [\u2139]  created namespace "kuard"\n2021-11-29 18:18:38 [\u2139]  created serviceaccount "kuard/kuard"\n2021-11-29 18:18:38 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-vault-vault"\n2021-11-29 18:18:38 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-cert-manager-cert-manager"\n2021-11-29 18:18:38 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-kube-system-aws-load-balancer-controller"\n2021-11-29 18:18:38 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-kube-system-ebs-csi-controller-sa"\n2021-11-29 18:18:38 [\u2139]  created namespace "vault"\n2021-11-29 18:18:39 [\u2139]  created serviceaccount "vault/vault"\n2021-11-29 18:18:39 [\u2139]  created namespace "cert-manager"\n2021-11-29 18:18:39 [\u2139]  created serviceaccount "cert-manager/cert-manager"\n2021-11-29 18:18:39 [\u2139]  created serviceaccount "kube-system/aws-load-balancer-controller"\n2021-11-29 18:18:39 [\u2139]  created serviceaccount "kube-system/ebs-csi-controller-sa"\n2021-11-29 18:18:41 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-external-dns-external-dns"\n2021-11-29 18:18:42 [\u2139]  created namespace "external-dns"\n2021-11-29 18:18:42 [\u2139]  created serviceaccount "external-dns/external-dns"\n2021-11-29 18:18:42 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-addon-iamserviceaccount-kube-system-efs-csi-controller-sa"\n2021-11-29 18:18:43 [\u2139]  created serviceaccount "kube-system/efs-csi-controller-sa"\n2021-11-29 18:18:43 [\u2139]  daemonset "kube-system/aws-node" restarted\n2021-11-29 18:18:43 [\u2139]  waiting for the control plane availability...\n2021-11-29 18:18:43 [\u2714]  saved kubeconfig as "/Users/ruzickap/git/k8s-eks-bottlerocket-fargate/kubeconfig-kube1.conf"\n2021-11-29 18:18:43 [\u2139]  no tasks\n2021-11-29 18:18:43 [\u2714]  all EKS cluster resources for "kube1" have been created\n2021-11-29 18:18:44 [\u2139]  kubectl command should work with "/Users/ruzickap/git/k8s-eks-bottlerocket-fargate/kubeconfig-kube1.conf", try \'kubectl --kubeconfig=/Users/ruzickap/git/k8s-eks-bottlerocket-fargate/kubeconfig-kube1.conf get nodes\'\n2021-11-29 18:18:44 [\u2714]  EKS cluster "kube1" in "eu-west-1" region is ready\ndaemonset.apps "aws-node" deleted\nconfigmap/calico-config created\ncustomresourcedefinition.apiextensions.k8s.io/bgpconfigurations.crd.projectcalico.org created\ncustomresourcedefinition.apiextensions.k8s.io/bgppeers.crd.projectcalico.org created\ncustomresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org created\ncustomresourcedefinition.apiextensions.k8s.io/clusterinformations.crd.projectcalico.org created\ncustomresourcedefinition.apiextensions.k8s.io/felixconfigurations.crd.projectcalico.org created\ncustomresourcedefinition.apiextensions.k8s.io/globalnetworkpolicies.crd.projectcalico.org created\ncustomresourcedefinition.apiextensions.k8s.io/globalnetworksets.crd.projectcalico.org created\ncustomresourcedefinition.apiextensions.k8s.io/hostendpoints.crd.projectcalico.org created\ncustomresourcedefinition.apiextensions.k8s.io/ipamblocks.crd.projectcalico.org created\ncustomresourcedefinition.apiextensions.k8s.io/ipamconfigs.crd.projectcalico.org created\ncustomresourcedefinition.apiextensions.k8s.io/ipamhandles.crd.projectcalico.org created\ncustomresourcedefinition.apiextensions.k8s.io/ippools.crd.projectcalico.org created\ncustomresourcedefinition.apiextensions.k8s.io/kubecontrollersconfigurations.crd.projectcalico.org created\ncustomresourcedefinition.apiextensions.k8s.io/networkpolicies.crd.projectcalico.org created\ncustomresourcedefinition.apiextensions.k8s.io/networksets.crd.projectcalico.org created\nclusterrole.rbac.authorization.k8s.io/calico-kube-controllers created\nclusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers created\nclusterrole.rbac.authorization.k8s.io/calico-node created\nclusterrolebinding.rbac.authorization.k8s.io/calico-node created\ndaemonset.apps/calico-node created\nserviceaccount/calico-node created\ndeployment.apps/calico-kube-controllers created\nserviceaccount/calico-kube-controllers created\nWarning: policy/v1beta1 PodDisruptionBudget is deprecated in v1.21+, unavailable in v1.25+; use policy/v1 PodDisruptionBudget\npoddisruptionbudget.policy/calico-kube-controllers created\n2021-11-29 18:18:59 [\u2139]  eksctl version 0.75.0\n2021-11-29 18:18:59 [\u2139]  using region eu-west-1\n2021-11-29 18:19:15 [\u2139]  nodegroup "managed-ng-1" will use "" [Bottlerocket/1.21]\n2021-11-29 18:19:32 [\u2139]  1 nodegroup (managed-ng-1) was included (based on the include/exclude rules)\n2021-11-29 18:19:32 [\u2139]  will create a CloudFormation stack for each of 1 managed nodegroups in cluster "kube1"\n2021-11-29 18:19:32 [\u2139]\n2 sequential tasks: { fix cluster compatibility, 1 task: { 1 task: { create managed nodegroup "managed-ng-1" } }\n}\n2021-11-29 18:19:32 [\u2139]  checking cluster stack for missing resources\n2021-11-29 18:19:41 [\u2139]  cluster stack has all required resources\n2021-11-29 18:19:41 [\u2139]  building managed nodegroup stack "eksctl-kube1-nodegroup-managed-ng-1"\n2021-11-29 18:19:41 [\u2139]  deploying stack "eksctl-kube1-nodegroup-managed-ng-1"\n2021-11-29 18:19:41 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-nodegroup-managed-ng-1"\n...\n2021-11-29 18:22:59 [\u2139]  waiting for CloudFormation stack "eksctl-kube1-nodegroup-managed-ng-1"\n2021-11-29 18:23:00 [\u2139]  no tasks\n2021-11-29 18:23:00 [\u2714]  created 0 nodegroup(s) in cluster "kube1"\n2021-11-29 18:23:00 [\u2139]  nodegroup "managed-ng-1" has 3 node(s)\n2021-11-29 18:23:00 [\u2139]  node "ip-192-168-31-11.eu-west-1.compute.internal" is ready\n2021-11-29 18:23:00 [\u2139]  node "ip-192-168-56-82.eu-west-1.compute.internal" is ready\n2021-11-29 18:23:00 [\u2139]  node "ip-192-168-60-184.eu-west-1.compute.internal" is ready\n2021-11-29 18:23:00 [\u2139]  waiting for at least 2 node(s) to become ready in "managed-ng-1"\n2021-11-29 18:23:00 [\u2139]  nodegroup "managed-ng-1" has 3 node(s)\n2021-11-29 18:23:00 [\u2139]  node "ip-192-168-31-11.eu-west-1.compute.internal" is ready\n2021-11-29 18:23:00 [\u2139]  node "ip-192-168-56-82.eu-west-1.compute.internal" is ready\n2021-11-29 18:23:00 [\u2139]  node "ip-192-168-60-184.eu-west-1.compute.internal" is ready\n2021-11-29 18:23:00 [\u2714]  created 1 managed nodegroup(s) in cluster "kube1"\n2021-11-29 18:23:12 [\u2139]  checking security group configuration for all nodegroups\n2021-11-29 18:23:12 [\u2139]  all nodegroups have up-to-date cloudformation templates\n'})}),"\n",(0,s.jsxs)(n.p,{children:["When the cluster is ready it immediately start pushing logs to CloudWatch under\n",(0,s.jsx)(n.code,{children:"/aws/eks/kube1/cluster"}),"."]}),"\n",(0,s.jsx)(n.p,{children:"Add add the user or role to the aws-auth ConfigMap. This is handy if you are\nusing different user for cli operations and different user/role for accessing\nthe AWS Console to see EKS Workloads in Cluster's tab."}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:'if ! eksctl get iamidentitymapping --cluster="${CLUSTER_NAME}" --region="${AWS_DEFAULT_REGION}" --arn=${AWS_CONSOLE_ADMIN_ROLE_ARN}; then\n  eksctl create iamidentitymapping --cluster="${CLUSTER_NAME}" --region="${AWS_DEFAULT_REGION}" --arn="${AWS_CONSOLE_ADMIN_ROLE_ARN}" --group system:masters --username admin\nfi\n'})}),"\n",(0,s.jsx)(n.p,{children:"Output:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-text",children:'2021-11-29 18:23:13 [\u2139]  eksctl version 0.75.0\n2021-11-29 18:23:13 [\u2139]  using region eu-west-1\n2021-11-29 18:23:14 [\u2139]  adding identity "arn:aws:iam::7xxxxxxxxxx7:role/AxxxxxxxxxxxxN" to auth ConfigMap\n'})}),"\n",(0,s.jsx)(n.p,{children:"Check the nodes+pods and max number of nodes which can be scheduled on one node:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"kubectl get nodes,pods -o wide --all-namespaces\n"})}),"\n",(0,s.jsx)(n.p,{children:"Output:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-text",children:"NAME                                                STATUS   ROLES    AGE   VERSION   INTERNAL-IP      EXTERNAL-IP     OS-IMAGE                               KERNEL-VERSION   CONTAINER-RUNTIME\nnode/ip-192-168-31-11.eu-west-1.compute.internal    Ready    <none>   81s   v1.21.6   192.168.31.11    54.194.69.158   Bottlerocket OS 1.4.1 (aws-k8s-1.21)   5.10.68          containerd://1.5.5+bottlerocket\nnode/ip-192-168-56-82.eu-west-1.compute.internal    Ready    <none>   86s   v1.21.6   192.168.56.82    3.250.52.238    Bottlerocket OS 1.4.1 (aws-k8s-1.21)   5.10.68          containerd://1.5.5+bottlerocket\nnode/ip-192-168-60-184.eu-west-1.compute.internal   Ready    <none>   84s   v1.21.6   192.168.60.184   54.75.89.58     Bottlerocket OS 1.4.1 (aws-k8s-1.21)   5.10.68          containerd://1.5.5+bottlerocket\n\nNAMESPACE     NAME                                           READY   STATUS    RESTARTS   AGE     IP               NODE                                           NOMINATED NODE   READINESS GATES\nkube-system   pod/calico-kube-controllers-6c85b56fcb-5g5cq   1/1     Running   0          4m16s   172.16.166.130   ip-192-168-56-82.eu-west-1.compute.internal    <none>           <none>\nkube-system   pod/calico-node-4whs8                          1/1     Running   0          84s     192.168.60.184   ip-192-168-60-184.eu-west-1.compute.internal   <none>           <none>\nkube-system   pod/calico-node-nbjsn                          1/1     Running   0          86s     192.168.56.82    ip-192-168-56-82.eu-west-1.compute.internal    <none>           <none>\nkube-system   pod/calico-node-nnhwz                          1/1     Running   0          81s     192.168.31.11    ip-192-168-31-11.eu-west-1.compute.internal    <none>           <none>\nkube-system   pod/coredns-7cc879f8db-ct5bp                   1/1     Running   0          21m     172.16.166.131   ip-192-168-56-82.eu-west-1.compute.internal    <none>           <none>\nkube-system   pod/coredns-7cc879f8db-h4mbs                   1/1     Running   0          21m     172.16.166.129   ip-192-168-56-82.eu-west-1.compute.internal    <none>           <none>\nkube-system   pod/kube-proxy-9c9wk                           1/1     Running   0          86s     192.168.56.82    ip-192-168-56-82.eu-west-1.compute.internal    <none>           <none>\nkube-system   pod/kube-proxy-gqbt7                           1/1     Running   0          81s     192.168.31.11    ip-192-168-31-11.eu-west-1.compute.internal    <none>           <none>\nkube-system   pod/kube-proxy-q7pzh                           1/1     Running   0          84s     192.168.60.184   ip-192-168-60-184.eu-west-1.compute.internal   <none>           <none>\n"})})]})}function d(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(u,{...e})}):u(e)}},8453:(e,n,t)=>{t.d(n,{R:()=>c,x:()=>r});var s=t(6540);const a={},o=s.createContext(a);function c(e){const n=s.useContext(o);return s.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:c(e.components),s.createElement(o.Provider,{value:n},e.children)}}}]);